{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6452249b-e8e6-4e4b-b0d1-924d3e6f695e",
   "metadata": {},
   "source": [
    "# Survey non-uniformity check pipeline:\n",
    "\n",
    "This notebook outlines my pipeline which mainly uses RAIL to check for any given choice of photo-z pipeline, the effect of survey non-uniformity.\n",
    "\n",
    "We will modify this notebook to make it into a RAIL pipeline; \n",
    "for this also c.f. `golden spike rail_pipelines` under the DESC directory making a pipeline class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1bc2f1-3ccd-4bf1-b2b2-451cee9731a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependences\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "\n",
    "import healpy as hp\n",
    "import pickle\n",
    "\n",
    "import pzflow\n",
    "from pzflow import Flow\n",
    "from pzflow.bijectors import Chain, ShiftBounds, RollingSplineCoupling\n",
    "from pzflow.examples import get_galaxy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc804d1-dd83-4036-a69a-2952aacbc2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import healpy as hp\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/global/homes/q/qhang/desc/notebooks_for_analysis/')\n",
    "import spatial_var_functions as svf\n",
    "import measure_properties_with_systematics as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cec3953-3633-4ed6-941e-94da7aba3674",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import RailStage stuff\n",
    "from rail.core.data import TableHandle\n",
    "from rail.core.stage import RailStage\n",
    "DS = RailStage.data_store\n",
    "DS.__class__.allow_overwrite = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e46370a-a726-4bf9-a8a4-445ad52448f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "cmap = matplotlib.cm.get_cmap('plasma')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0b1c9d-f06b-4418-8f7b-bc6bafbe8ede",
   "metadata": {},
   "source": [
    "### Pre-defined functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef74504-8f59-448b-ab18-cbc7c66254ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here put together a function to assign the error and save, then loop 10 times\n",
    "\n",
    "def assign_pixels_to_gals(Ngal, pixels, random_seed=10):\n",
    "    # set random seed\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "    npix = len(pixels)\n",
    "    print('Average no. of gal per pix: ', Ngal/npix)\n",
    "    \n",
    "    # generate a uniform distribution between 0 to 1 for each galaxy\n",
    "    rand = np.random.uniform(size=Ngal)\n",
    "    \n",
    "    pixel_index = np.digitize(rand, np.linspace(0,1, npix + 1))\n",
    "    pixel_index -= 1\n",
    "\n",
    "    assigned_pixels = pixels[pixel_index]\n",
    "    return assigned_pixels\n",
    "\n",
    "\n",
    "def assign_obs_cond_to_gals(assigned_pixels, obs_cond, mask, sys, bands):\n",
    "    \n",
    "    assigned_obs_cond = {}\n",
    "    \n",
    "    for key in sys:\n",
    "        assigned_obs_cond[key] = {}\n",
    "        for b in bands:\n",
    "            temp = np.zeros(len(mask))\n",
    "            temp[mask.astype(bool)] = obs_cond[key][b]\n",
    "            assigned_obs_cond[key][b] = temp[assigned_pixels]\n",
    "    \n",
    "    return assigned_obs_cond\n",
    "    \n",
    "\n",
    "    \n",
    "def get_semi_major_minor(data, scale=1):\n",
    "\n",
    "    q = (1 - data['ellipticity'])/(1 + data['ellipticity'])\n",
    "    ai = data['size']\n",
    "    bi = ai*q\n",
    "\n",
    "    ai = ai.to_numpy()*scale\n",
    "    bi = bi.to_numpy()*scale\n",
    "    \n",
    "    return ai, bi\n",
    "\n",
    "\n",
    "def compute_mag_err(mag, ai, bi, assigned_obs_cond, obs_cond, band='u', m5key='coaddm5_per_visit'):\n",
    "    \n",
    "    A_ratio = svf.get_area_ratio_auto(ai, bi, assigned_obs_cond['theta'][band])\n",
    "    err = svf.compute_sigma_rand_sq(\n",
    "        assigned_obs_cond[m5key][band], \n",
    "        mag, \n",
    "        obs_cond['gamma'][band],\n",
    "        assigned_obs_cond['nvis'][band],  \n",
    "        A_ratio=A_ratio\n",
    "    )\n",
    "    err = svf.compute_magerr_lsstmodel(\n",
    "        err, \n",
    "        obs_cond['sigmasys'], \n",
    "        highSNR=True\n",
    "    )\n",
    "    magerr = err*obs_cond['calibration']['magerrscale'][band]\n",
    "        \n",
    "    return magerr\n",
    "\n",
    "\n",
    "def assign_new_mag_magerr(data, magerr, ai, bi, assigned_obs_cond, obs_cond, bands, rng):\n",
    "\n",
    "    totObsIndex = 1\n",
    "    ObsMags = np.zeros((len(data), len(bands)))\n",
    "    ObsMagsErr = np.zeros((len(data), len(bands)))\n",
    "     \n",
    "    for ii, b in enumerate(bands):\n",
    "\n",
    "        nsr = magerr[b]\n",
    "        mags = data[b].to_numpy()\n",
    "\n",
    "        # calculate observed magnitudes\n",
    "        fluxes = 10 ** (mags / -2.5)\n",
    "        obsFluxes = fluxes * (1 + rng.normal(scale=nsr))\n",
    "        \n",
    "        with np.errstate(divide=\"ignore\"):\n",
    "            newmags = -2.5 * np.log10(np.clip(obsFluxes, 0, None))\n",
    "\n",
    "        #index for selecting samples within the \n",
    "        ind = newmags<obs_cond['sigLim'][b]\n",
    "        \n",
    "        totObsIndex *= ind\n",
    "        \n",
    "        # new magnitudes:\n",
    "        newmags[~ind] = np.nan\n",
    "        ObsMags[:,ii] = np.copy(newmags)\n",
    "        \n",
    "        # new errors:\n",
    "        \n",
    "        mag = ObsMags[:,ii]\n",
    "        ObsMagsErr[:,ii] = compute_mag_err(mag, ai, bi, assigned_obs_cond, \n",
    "                             obs_cond, band=b, m5key='coaddm5_per_visit')\n",
    "    totObsIndex = totObsIndex.astype(bool)\n",
    "    \n",
    "    return totObsIndex, ObsMags, ObsMagsErr\n",
    "\n",
    "\n",
    "def join_tables_and_save(data, ObsMags, ObsMagsErr, pixels, totObsIndex, outfile):\n",
    "\n",
    "    df = data.copy()\n",
    "    magDf = pd.DataFrame(\n",
    "                ObsMags, columns=[f\"ObsMag_{band}\" for band in bands], index=data.index\n",
    "            )\n",
    "    errDf = pd.DataFrame(\n",
    "                ObsMagsErr, columns=[f\"ObsMagErr_{band}\" for band in bands], index=data.index\n",
    "            )\n",
    "    pixDf = pd.DataFrame(\n",
    "                pixels, columns = ['pixels'], index=data.index,\n",
    "    )\n",
    "\n",
    "    obsCatalog = pd.concat([df, magDf], axis=1)\n",
    "    obsCatalog = pd.concat([obsCatalog, errDf], axis=1)\n",
    "    obsCatalog = pd.concat([obsCatalog, pixDf],axis=1)\n",
    "\n",
    "    #finally select the indices to use:\n",
    "    savecat = obsCatalog.loc[totObsIndex, :]\n",
    "\n",
    "    svf.dump_save(savecat, outfile)\n",
    "    \n",
    "    print(f\"Saved: {outfile}.\")\n",
    "    \n",
    "    \n",
    "def obs_cond_pipeline(data, usepixels, random_seed, rng, obs_cond, mask, sys, bands, outfile,\n",
    "                      m5key='coaddm5_per_visit'):\n",
    "    \n",
    "    Ngal = len(mock_tract)\n",
    "\n",
    "    assigned_pixels = assign_pixels_to_gals(Ngal, usepixels, random_seed=random_seed)\n",
    "    #print('flag1')\n",
    "\n",
    "    assigned_obs_cond = assign_obs_cond_to_gals(assigned_pixels, obs_cond, mask, sys, bands)\n",
    "    #print('flag2')\n",
    "    \n",
    "    # assign photo-z errors:\n",
    "    scale = obs_cond['calibration']['abscale']\n",
    "    ai, bi = get_semi_major_minor(data, scale=scale)\n",
    "    \n",
    "    magerr = {}\n",
    "    for b in bands:\n",
    "        mag = data[b].to_numpy()\n",
    "        magerr[b] = compute_mag_err(mag, ai, bi, assigned_obs_cond, \n",
    "                                 obs_cond, band=b, m5key='coaddm5_per_visit')\n",
    "    #print('flag3')\n",
    "\n",
    "    # apply error to get new magnitudes, compute new magnitudes, \n",
    "    # and cut objects beyond magnitude limits:\n",
    "    rng = np.random.default_rng(10)\n",
    "    totObsIndex, ObsMags, ObsMagsErr = assign_new_mag_magerr(data, magerr, ai, bi, \n",
    "                                                             assigned_obs_cond, \n",
    "                                                             obs_cond, bands, rng)\n",
    "    #print('flag4')\n",
    "\n",
    "    join_tables_and_save(data, ObsMags, ObsMagsErr, assigned_pixels, totObsIndex, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565876f6-7ab1-4137-955e-c8acb7eecef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here load each set and pass on to FZBoost, extract zmode, \n",
    "# delete the output file (or re-write each time and delete later),\n",
    "# save the zmode file\n",
    "import tables_io\n",
    "\n",
    "def convert_catalog_to_test_data(data, DS, bands):\n",
    "\n",
    "    data2 = OrderedDict()\n",
    "\n",
    "    key1 = 'ObsMagErr_'\n",
    "    key2 = 'ObsMag_'\n",
    "\n",
    "    for bb in bands:\n",
    "        data2['mag_err_%s_lsst'%bb] = data[key1 + bb].to_numpy()\n",
    "        data2['mag_%s_lsst'%bb] = data[key2 + bb].to_numpy()\n",
    "\n",
    "    data2['redshift'] = data['redshift'].to_numpy()\n",
    "\n",
    "    xtest_data = tables_io.convert(data2, tables_io.types.NUMPY_DICT)\n",
    "    test_data = DS.add_data(\"test_data\", xtest_data, TableHandle)\n",
    "    \n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9f0bdc-81b9-49a4-b896-9ea31f99769c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nz_meanz(pz, truez, pzbins, nbootstrap, zlim = [0,2.0], bins=100):\n",
    "    \n",
    "    nztrue = {}\n",
    "    meanztrue = np.zeros(len(pzbins)-1)\n",
    "    stdmeanz = np.zeros(len(pzbins)-1)\n",
    "    \n",
    "    for ii in range(len(pzbins)-1):\n",
    "        ind = (pz>= pzbins[ii])&(pz < pzbins[ii+1])\n",
    "        ind = ind.flatten()\n",
    "        cc = np.histogram(truez[ind], range=zlim, bins=bins)\n",
    "        \n",
    "        zz = (cc[1][1:] + cc[1][:-1])*0.5\n",
    "        nztrue[ii] = np.c_[zz,cc[0]]\n",
    "        \n",
    "        # calculate true mean z\n",
    "        #meanztrue[ii] = np.mean(truez[ind])\n",
    "        meanztrue[ii] = np.sum(cc[0] * zz)/np.sum(cc[0])\n",
    "        \n",
    "        \n",
    "        # stdmeanz using bootstrap method:\n",
    "        sampholder = np.zeros(nbootstrap)\n",
    "    \n",
    "        data = truez[ind]\n",
    "        for kk in range(nbootstrap):\n",
    "            samp = np.random.choice(data, \n",
    "                            size=len(data),\n",
    "                            replace=True)\n",
    "            # repeat the operation \n",
    "            cc = np.histogram(samp, range=zlim, bins=bins)\n",
    "            sampholder[kk] = np.sum(cc[0] * zz)/np.sum(cc[0])\n",
    "            #sampholder[kk] = np.mean(samp)\n",
    "        stdmeanz[ii] = np.std(sampholder)\n",
    "        \n",
    "    return nztrue, meanztrue, stdmeanz "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c468f266-271a-4a4f-bfe2-87bb595d7cf4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 1: Load pre-trained flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd1c95d-d815-48a2-b038-5259d8cad586",
   "metadata": {},
   "outputs": [],
   "source": [
    "photFlow = Flow(file = \"/export/donatello/qhang/nersc_local/main_galaxy_flow/flow.pzflow.pkl\")\n",
    "shapeFlow = Flow(file = \"/export/donatello/qhang/nersc_local/conditional_galaxy_flow/flow.pzflow.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31195b9a-0676-44d5-966c-2d729e1a1e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraction of sample with the i-band limit at Y5 is about 30%\n",
    "Ngal_gen = int(160000/0.3)\n",
    "print(Ngal_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf30948-3153-4dfb-b576-4e4f8464a952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first sample the redshifts and photometry\n",
    "photoCat = photFlow.sample(Ngal_gen, seed=0)\n",
    "\n",
    "# then add in the sizes and ellipticities\n",
    "fullCat = shapeFlow.sample(conditions=photoCat, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e5c3bd-68a4-45eb-b3fc-2209bdc0d9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now apply the cut and save:\n",
    "\n",
    "sel = fullCat['i']<25\n",
    "sel = sel & (fullCat['u']<25.7)\n",
    "sel = sel & (fullCat['g']<27.0)\n",
    "sel = sel & (fullCat['r']<27.1)\n",
    "sel = sel & (fullCat['z']<25.7)\n",
    "sel = sel & (fullCat['y']<24.5)\n",
    "\n",
    "print(len(fullCat['i'][sel]))\n",
    "\n",
    "# save\n",
    "mock_tract = fullCat.loc[sel, :]\n",
    "\n",
    "svf.dump_save(mock_tract, 'cosmoDC2_pzflow_sample_single_tract.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0863cfec-96ba-4624-9cb9-91fae8a8008a",
   "metadata": {},
   "source": [
    "### Step 2: Load systematic maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566cdb41-ac68-4e66-a459-efecb0d45fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/pscratch/sd/q/qhang/'\n",
    "bands = ['u','g','r','i','z','y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc37f27-5988-4fbb-bf9e-5f9b82b32fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wfd_DESI_overlap(scratch):\n",
    "    fname = scratch + \"rubin_baseline_v2/\"\n",
    "    fname += \"wfd_footprint_nvisitcut_500_nside_128.fits\"\n",
    "    wfd_mask = hp.read_map(fname)\n",
    "    \n",
    "    fname = scratch + \"rubin_baseline_v2/\"\n",
    "    fname += \"DESI_footprint_completeness_mask_128.fits\"\n",
    "\n",
    "    desi_mask = hp.read_map(fname)\n",
    "\n",
    "    desi_mask[desi_mask<=0]=0\n",
    "    desi_mask[desi_mask>0]=1\n",
    "    \n",
    "    pix = np.arange(len(wfd_mask))\n",
    "    overlap_mask = wfd_mask*desi_mask\n",
    "    overlap_pix = pix[overlap_mask.astype(bool)]\n",
    "    return wfd_mask, desi_mask, overlap_pix\n",
    "\n",
    "wfd_mask, desi_mask, overlap_pix = get_wfd_DESI_overlap(root)\n",
    "overlap_mask = wfd_mask*desi_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cbae54-4e1e-44c0-b7c7-fa4512a507a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here load the observing cnoditions (Y1/Y5):\n",
    "# load the Y1 baseline maps\n",
    "# opsim directory\n",
    "Opsimdir = root + 'rubin_baseline_v2/MAF-1year/'\n",
    "\n",
    "# Here load the median 5sigma depth map in each band:\n",
    "\n",
    "metric_dict = {'theta':'Median_seeingFwhmEff',\n",
    "               'coaddm5':'CoaddM5',\n",
    "               'nvis':'Nvisits',}\n",
    "\n",
    "mask = wfd_mask\n",
    "\n",
    "obs_cond = {}\n",
    "\n",
    "for key in metric_dict.keys():\n",
    "    print(f'Loading {key}...')\n",
    "    name = metric_dict[key]\n",
    "    obs_cond[key] = {}\n",
    "    for b in bands:\n",
    "        fname = Opsimdir+'baseline_v2_0_10yrs_%s_%s_and_nightlt365_HEAL.fits'%(name, b)\n",
    "        fin1=hp.read_map(fname)\n",
    "        obs_cond[key][b] = fin1[mask.astype(bool)]\n",
    "\n",
    "# converting coaddm5 into m5 for single visit\n",
    "obs_cond['coaddm5_per_visit']={}\n",
    "for ii, b in enumerate(bands):\n",
    "    delta_mag = 2.5*np.log10(np.sqrt(obs_cond['nvis'][b]/1.))\n",
    "    obs_cond['coaddm5_per_visit'][b] = obs_cond['coaddm5'][b] - delta_mag\n",
    "    \n",
    "# load combined coadd depth:\n",
    "#print('Loading combined coaddm5...')\n",
    "#name = 'CoaddM5'\n",
    "#fname = Opsimdir+'minion_1016_dc2_%s_nightlt365_HEAL.fits'%(name)\n",
    "#fin1=hp.read_map(fname)\n",
    "#obs_cond['coaddm5']['comb'] = fin1[mask.astype(bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd1cb80-7212-4d69-a629-1c5816df0bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_cond['gamma'] = {\n",
    "    'u':0.038,\n",
    "    'g':0.039,\n",
    "    'r':0.039,\n",
    "    'i':0.039,\n",
    "    'z':0.039,\n",
    "    'y':0.039,\n",
    "}\n",
    "obs_cond['sigmasys'] = 0\n",
    "\n",
    "# add calibration\n",
    "obs_cond['calibration'] = {}\n",
    "obs_cond['calibration']['abscale']=1/2.5,\n",
    "obs_cond['calibration']['magerrscale']={\n",
    "    'u': 0.73,\n",
    "    'g': 1.20,\n",
    "    'r': 0.98, \n",
    "    'i': 1.10,\n",
    "    'z': 1.10,\n",
    "    'y': 1.15,\n",
    "}\n",
    "\n",
    "obs_cond['sigLim'] = {\n",
    "    'u': 24.9, \n",
    "    'g': 26.2, \n",
    "    'r': 26.3, \n",
    "    'i': 24.1, \n",
    "    'z': 24.9, \n",
    "    'y': 23.7,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b0e7c2-0b15-4809-a766-bc67648e9e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here split into 10 sets of pixels in i-band coadd depth:\n",
    "ranges=[24.6, 25.7]\n",
    "nquantiles = 20\n",
    "sysmap = np.zeros(len(mask))\n",
    "sysmap[mask.astype(bool)] = obs_cond['coaddm5']['i']\n",
    "\n",
    "# define the bins \n",
    "qtl = np.linspace(ranges[0], ranges[1], nquantiles+1)\n",
    "added_range=False\n",
    "selected_pix = mp.select_pixels_from_sysmap(sysmap, mask, qtl, added_range=added_range)\n",
    "print(len(selected_pix))\n",
    "\n",
    "# calculate the mean and median value of sysmap in each quantile\n",
    "mean_sys = np.zeros(nquantiles)\n",
    "median_sys = np.zeros(nquantiles)\n",
    "for ii in range(nquantiles):\n",
    "    pix = selected_pix[ii]\n",
    "    mean_sys[ii] = np.mean(sysmap[pix])\n",
    "    median_sys[ii] = np.median(sysmap[pix])\n",
    "#print('mean sys: ', mean_sys)\n",
    "#print('median sys: ', median_sys)\n",
    "plt.plot(mean_sys, label='mean_sys')\n",
    "plt.plot(median_sys, label='median_sys')\n",
    "plt.legend()\n",
    "plt.xlabel('bin number')\n",
    "plt.ylabel('i-band coadd depth (Y1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e8205f-05c6-497e-80a3-4c5b234e9882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here load the PZflow testing sample:\n",
    "# in this case, we use the signle tract sample \n",
    "\n",
    "\n",
    "mock_tract = svf.dump_load('cosmoDC2_pzflow_sample_single_tract.pkl')\n",
    "mock_tract.head()\n",
    "\n",
    "print(\"Number of obj in this sample: \", len(mock_tract))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edef396-d915-4427-b5c7-7619bb06d2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get obs cond\n",
    "random_seed=10\n",
    "rng = np.random.default_rng(10)\n",
    "sys = ['coaddm5_per_visit', 'nvis', 'theta']\n",
    "\n",
    "data = mock_tract\n",
    "\n",
    "for q in range(len(selected_pix)):\n",
    "    usepixels = selected_pix[q]\n",
    "\n",
    "    outfile = '/pscratch/sd/q/qhang/PZflow-samples/baselinev2.0-test/y1/'\n",
    "    outfile += 'cosmoDC2_pzflow_sample_obs_cal-coaddm5-i-qtl-%s.pkl'%q\n",
    "    \n",
    "    obs_cond_pipeline(data, usepixels, random_seed, rng, obs_cond, mask, sys, bands, outfile,\n",
    "                      m5key='coaddm5_per_visit')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b350d66-d18d-4dd7-add8-1b8cf7325d21",
   "metadata": {},
   "source": [
    "### Step 3: run photo-z estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605c7fc1-d678-4318-a506-60e85b44bc75",
   "metadata": {},
   "source": [
    "#### Here is an example of FZboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddd2d8e-4ce9-4b33-b740-87f97861d567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rail.estimation.algos.flexzboost import Inform_FZBoost, FZBoost\n",
    "\n",
    "fz_modelfile = 'FZB_test.pkl'\n",
    "pzflex = FZBoost.make_stage(name='fzboost', hdf5_groupname='',\n",
    "                            model='FZB_test.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f4a2c3-d250-40fc-b163-6b2015adf7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q=0\n",
    "\n",
    "for q in range(1,len(selected_pix)):\n",
    "    print(\"Working on qtl %d\"%q)\n",
    "    \n",
    "    root = '/pscratch/sd/q/qhang/PZflow-samples/DC2-test/'\n",
    "    fname = root + 'cosmoDC2_pzflow_sample_minion_1016_y1_obs_cal-coaddm5-i-qtl-%s.pkl'%q\n",
    "    data = svf.dump_load(fname)\n",
    "\n",
    "    test_data = convert_catalog_to_test_data(data, DS, bands)\n",
    "\n",
    "    fzresults = pzflex.estimate(test_data)\n",
    "\n",
    "    # obtain the mode:\n",
    "    zgrid = np.linspace(0, 3., 301)\n",
    "    fz_modes = fzresults().mode(grid=zgrid)\n",
    "\n",
    "    # save:\n",
    "    fname = root + 'cosmoDC2_pzflow_sample_minion_1016_y1_obs_cal-coaddm5-i-qtl-%s-zmode.pkl'%q\n",
    "    svf.dump_save(fz_modes, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e656574-5c1f-4b5f-8ee3-feac76b74136",
   "metadata": {},
   "source": [
    "#### Here is an example of BPZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e827983a-e9f6-44fc-bf09-1c5306b529bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rail.estimation.algos.bpz_lite import BPZ_lite\n",
    "\n",
    "band_names = [\n",
    "    'mag_u_lsst','mag_g_lsst','mag_r_lsst',\n",
    "    'mag_i_lsst','mag_z_lsst','mag_y_lsst'  \n",
    "]\n",
    "\n",
    "band_err_names = [\n",
    "    'mag_err_u_lsst','mag_err_g_lsst','mag_err_r_lsst',\n",
    "    'mag_err_i_lsst','mag_err_z_lsst','mag_err_y_lsst'\n",
    "]\n",
    "prior_band='mag_i_lsst'\n",
    "\n",
    "\n",
    "output = \"newBPZ_test.hdf5\"\n",
    "\n",
    "# mag_limits change to Y1 limits:\n",
    "estimate_bpz = BPZ_lite.make_stage(name='estimate_bpz', hdf5_groupname='', \n",
    "                                   #columns_file=inroot+'test_bpz.columns',\n",
    "                                   #prior_file='CWW_HDFN_prior.pkl',\n",
    "                                   nondetect_val=np.nan, #spectra_file='SED/CWWSB4.list',\n",
    "                                   band_names=band_names,\n",
    "                                   band_err_names=band_err_names,\n",
    "                                   prior_band=prior_band,\n",
    "                                   mag_limits = dict(mag_u_lsst=27.79,\n",
    "                                                mag_g_lsst=29.04,\n",
    "                                                mag_r_lsst=29.06,\n",
    "                                                mag_i_lsst=28.62,\n",
    "                                                mag_z_lsst=27.98,\n",
    "                                                mag_y_lsst=27.05),\n",
    "                                   output=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519cd7d8-2657-47cc-8f13-af454c20c323",
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in range(len(selected_pix)):\n",
    "    print(\"Working on qtl %d\"%q)\n",
    "    \n",
    "    root = '/pscratch/sd/q/qhang/PZflow-samples/baselinev2.0-test/y1/'\n",
    "    fname = root + 'cosmoDC2_pzflow_sample_obs_cal-coaddm5-i-qtl-%s.pkl'%q\n",
    "    data = svf.dump_load(fname)\n",
    "\n",
    "    test_data = convert_catalog_to_test_data(data, DS, bands)\n",
    "\n",
    "    bpz_estimated = estimate_bpz.estimate(test_data)\n",
    "\n",
    "    # obtain the mode:\n",
    "    zmode = bpz_estimated().ancil['zmode']\n",
    "\n",
    "    # save:\n",
    "    fname = root + 'bpz/cosmoDC2_pzflow_sample_obs_cal-coaddm5-i-qtl-%s-zmode.pkl'%q\n",
    "    svf.dump_save(zmode, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215bb532-2df5-4b4e-83cc-a3d5f9cbd0a3",
   "metadata": {},
   "source": [
    "### Step 4: Check the shift in mean redshifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabe504e-1d5a-47b7-aaf0-cebdd0dfe5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally load all in terms of pz bins and compare true n(z)\n",
    "\n",
    "NZTRUE = {}\n",
    "MEANZTRUE = {}\n",
    "STDMEANZ = {}\n",
    "\n",
    "for q in range(20):\n",
    "\n",
    "    root = '/pscratch/sd/q/qhang/PZflow-samples/baselinev2.0-test/y1/'\n",
    "    fname = root + 'bpz/cosmoDC2_pzflow_sample_obs_cal-coaddm5-i-qtl-%s-zmode.pkl'%q\n",
    "    pz = svf.dump_load(fname)\n",
    "\n",
    "    fname = root + 'cosmoDC2_pzflow_sample_obs_cal-coaddm5-i-qtl-%s.pkl'%q\n",
    "    cat = svf.dump_load(fname)\n",
    "    truez = cat['redshift'].to_numpy()\n",
    "\n",
    "    pzbins = np.linspace(0.2,1.2,5+1)\n",
    "    nbootstrap = 1000\n",
    "    nztrue, meanztrue, stdmeanz = get_nz_meanz(pz, truez, pzbins, nbootstrap)\n",
    "\n",
    "    # output these quantites:\n",
    "    \n",
    "    NZTRUE[q] = nztrue\n",
    "    MEANZTRUE[q] = meanztrue\n",
    "    STDMEANZ[q] = stdmeanz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdeaf6a-008d-445a-8b79-a24252e242d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.zeros(5)\n",
    "\n",
    "# weight should be number of pixels in the qtl: len(selected_pix[q])\n",
    "\n",
    "for ii in range(5):\n",
    "    dist = 0\n",
    "    for q in range(20):\n",
    "        w = len(selected_pix[q])/sum(mask)\n",
    "        dist += NZTRUE[q][ii][:,1]*w\n",
    "    #compute mean\n",
    "    mean[ii] = np.sum(dist * NZTRUE[q][ii][:,0])/np.sum(dist)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917ab6e2-79b5-4ad7-b3f7-74c245488e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nquantiles = 20\n",
    "\n",
    "fig,axarr=plt.subplots(2,5,figsize=[15,5],gridspec_kw={'height_ratios': [3, 1]})\n",
    "for ii in range(5):\n",
    "    plt.sca(axarr[0,ii])\n",
    "    for q in range(nquantiles):\n",
    "        colorlab = q/(nquantiles*1.2)\n",
    "        dzz = NZTRUE[q][ii][1,0] - NZTRUE[q][ii][0,0]\n",
    "        plt.plot(NZTRUE[q][ii][:,0], NZTRUE[q][ii][:,1]/np.sum(NZTRUE[q][ii][:,1])/dzz, \n",
    "                color=cmap(colorlab))\n",
    "    #plt.xlim([0,2])\n",
    "    plt.ylim([0,4.1])\n",
    "    plt.plot([mean[ii], mean[ii]], [0, 4.1],'k')\n",
    "    plt.text(0.6, 3.5, \"%.2f < z(BPZ) < %.2f\"%(pzbins[ii], pzbins[ii+1]))\n",
    "    plt.yticks([])\n",
    "    plt.xlabel(\"z (truth)\")\n",
    "    \n",
    "    plt.sca(axarr[1, ii])\n",
    "    for q in range(nquantiles):\n",
    "        colorlab = q/(nquantiles*1.2)\n",
    "        plt.errorbar(mean_sys[q], MEANZTRUE[q][ii]-mean[ii], yerr=STDMEANZ[q][ii],fmt='o',\n",
    "                    color=cmap(colorlab))\n",
    "    dz = 0.005*(1+mean[ii])\n",
    "    \n",
    "    plt.plot([24.6, 25.7], [0, 0], 'k-', alpha=0.5)\n",
    "    plt.fill_between([24.6, 25.7], [-dz, -dz], \n",
    "                    [dz, dz],color='k',alpha=0.2)\n",
    "    if ii==0:\n",
    "        plt.ylabel(\"$z - \\\\langle z\\\\rangle$\")\n",
    "    if ii>0:\n",
    "        plt.yticks([])\n",
    "    plt.xlabel(\"$i$ (Coadd, 1-year)\")\n",
    "    plt.ylim([-0.015,0.015])\n",
    "    plt.xlim([24.6, 25.7])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.saveifg('fig.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10511a44-b3b6-41ef-98f0-5b14753ff071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d3ec01-ba84-49ce-8d5f-cc400ef8f74d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condarail",
   "language": "python",
   "name": "condarail"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
